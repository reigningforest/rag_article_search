# Agentic RAG: Web-Based Retrieval-Augmented Generation System

## Project Overview

This project provides a web-based interface for intelligent research paper search and analysis. The system combines advanced RAG techniques with Google Gemini AI to deliver accurate, contextual answers about ArXiv research papers.

## System Architecture

The agentic RAG system follows these key steps:

1. **Query Classification**: Determines if query requires arXiv paper retrieval using Gemini
2. **Query Rewriting**: Generates optimized query variation for better retrieval using Gemini
3. **Document Retrieval**: Semantic search using rewritten query with Pinecone vector database
4. **Response Generation**: Final answer generation using Gemini with retrieved abstracts
5. **Abstract Simplification**: AI-powered simplification of complex abstracts for easier comprehension

The system provides real-time progress tracking and outputs both the main response and simplified source documents.

## Project Structure

```
rag_article_search/
â”œâ”€â”€ main_app.py                   # Web interface (Streamlit)
â”œâ”€â”€ main_cli.py                   # Command-line interface
â”œâ”€â”€ src/                          # Core system modules
â”‚   â”œâ”€â”€ rag/                      # RAG workflow components
â”‚   â”‚   â”œâ”€â”€ state.py              # RAG state definition
â”‚   â”‚   â”œâ”€â”€ rag_graph.py          # Graph workflow builder
â”‚   â”‚   â””â”€â”€ nodes/                # Individual workflow nodes
â”‚   â”‚       â”œâ”€â”€ classification.py
â”‚   â”‚       â”œâ”€â”€ query_processing.py
â”‚   â”‚       â”œâ”€â”€ retrieval.py
â”‚   â”‚       â”œâ”€â”€ response_generation.py
â”‚   â”‚       â””â”€â”€ simplify.py
â”‚   â”œâ”€â”€ models/                   # Model management
â”‚   â”‚   â””â”€â”€ model_loader.py       # Gemini, embeddings setup
â”‚   â”œâ”€â”€ connections/              # External service connections
â”‚   â”‚   â”œâ”€â”€ pinecone_db.py        # Vector database operations
â”‚   â”‚   â””â”€â”€ gemini_query.py       # Google Gemini integration
â”‚   â””â”€â”€ loaders/                  # Data processing utilities
â”‚       â”œâ”€â”€ data_loader.py        # Dataset management
â”‚       â””â”€â”€ embedding.py          # Embedding operations
â”œâ”€â”€ scripts/                      # Background processing
â”‚   â””â”€â”€ get_data_pipeline.py      # Data download and processing
â”œâ”€â”€ config/                       # Configuration
â”‚   â””â”€â”€ config.yaml               # System settings
â”œâ”€â”€ data/                         # Processed data storage
â””â”€â”€ output/                       # Results and visualizations
```ted Generation System

An intelligent web application for searching and analyzing ArXiv research papers using advanced Retrieval-Augmented Generation (RAG) with Google Gemini. Features a user-friendly Streamlit interface with smart data management and query processing.

## Quick Start

1. **Install dependencies:**
   ```bash
   poetry install  # or pip install -r requirements.txt
   ```

2. **Set up environment variables:**
   ```bash
   # Create .env file with your API keys
   GEMINI_API_KEY=your_gemini_api_key
   PINECONE_API_KEY=your_pinecone_api_key
   ```

3. **Set up Kaggle authentication:**
   - Download `kaggle.json` from [Kaggle Settings](https://www.kaggle.com/settings) â†’ API
   - Place at: `~/.kaggle/kaggle.json` (Linux/Mac) or `C:\Users\{username}\.kaggle\kaggle.json` (Windows)

3. **Launch the web application:**
   ```bash
   streamlit run streamlit_app.py
   ```

4. **First time setup:** Use the web interface to download and process ArXiv data
5. **Start querying:** Ask questions about research papers!

## Project Overview

This project provides a web-based interface for intelligent research paper search and analysis. The system combines advanced RAG techniques with Google Gemini AI to deliver accurate, contextual answers about ArXiv research papers.

## Features

- **ğŸŒ Web Interface**: Clean Streamlit app for searching research papers
- **ğŸ’» Multiple Entry Points**: Web UI, CLI, and programmatic access
- **ğŸ¤– Agentic RAG**: Intelligent query processing and response generation
- **â˜ï¸ Google Gemini Integration**: Powered by Google Gemini 2.0 Flash
- **ğŸ§  Fine-tuned Model**: SmolLM2 model for enhanced abstract simplification (GPU accelerated)
- **ğŸ—ƒï¸ Vector Database**: Pinecone integration for semantic search
- **ğŸ“„ Simplified Abstracts**: AI-powered simplification of complex research papers
- **â±ï¸ Real-time Progress**: Live progress tracking during processing

## Installation

```bash
# Clone repository
git clone <repository-url>
cd rag_article_search

# Install dependencies
poetry install
# OR
pip install -r requirements.txt
```

**GPU Support**: CUDA-compatible GPU recommended for optimal performance with fine-tuned model

## Environment Variables

Create a `.env` file in the project root:

```env
GEMINI_API_KEY=your_gemini_api_key_here
PINECONE_API_KEY=your_pinecone_api_key_here
```

**Get API Keys:**
- **Gemini**: [Google AI Studio](https://makersuite.google.com/app/apikey)
- **Pinecone**: [Pinecone Console](https://app.pinecone.io/)

**Kaggle Setup** (for data download):
1. Download `kaggle.json` from [Kaggle Settings](https://www.kaggle.com/settings) â†’ API
2. Place at: `~/.kaggle/kaggle.json` (Linux/Mac) or `C:\Users\{username}\.kaggle\kaggle.json` (Windows)

## Usage

### Web Interface (Recommended)
```bash
streamlit run main_app.py
```

### Command Line Interface
```bash
python main_cli.py "Your research question here"
```

### Programmatic Usage
```python
from main_app import main
result = main("Your research question here")
```

### First Time Setup
- Click "Run Data Pipeline" in the web interface to download and process ArXiv data
- Wait for processing to complete (may take several hours)
- Then start asking questions about research papers!
- **Model Selection**: Configure `use_finetuned: true/false` in `config/config.yaml` to switch between fine-tuned and Gemini models

The system shows real-time progress and outputs both the main response and simplified source documents.